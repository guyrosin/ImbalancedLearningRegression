{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IoG91SaLwtuq"
      },
      "source": [
        "# ImbalancedLearningRegression (0.0.1): Usage\n",
        "---\n",
        "## SMOGNBoost\n",
        "Amit Shanbhoug, 8677407 \\\n",
        "Adapted from Nick Kunz's SMOGN package: https://github.com/nickkunz/smogn/blob/master/examples/smogn_example_1_beg.ipynb\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YOSHCUHR--nw"
      },
      "source": [
        "## Installation\n",
        "\n",
        "First, we install ImbalancedLearningRegression from the Github repository. Alternatively, we could install from the official PyPI distribution. However, the developer version is utilized here for the latest release. Works on Kernel: python 3.10.7, there may be some issues if you run with a different version, older or newer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9SqBgJ8rduy"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "## suppress install output\n",
        "\n",
        "## install pypi release\n",
        "# !pip install ImbalancedLearningRegression\n",
        "\n",
        "## install developer version\n",
        "# !pip install git+https://github.com/paobranco/ImbalancedLearningRegression.git"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gKhs9eJd_Ab6"
      },
      "source": [
        "## Dependencies\n",
        "Next, we load the required dependencies. Here we import `ImbalancedLearningRegression` to later apply Synthetic Minority Over-Sampling Technique for Regression with Gaussian Noise. In addition, we use `pandas` for data handling, and `seaborn` to visualize our results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fPB6tSLinAFS"
      },
      "outputs": [],
      "source": [
        "## load dependencies\n",
        "## load libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import math\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "from ImbalancedLearningRegression.smogn import smogn\n",
        "from ImbalancedLearningRegression.smogn_boost import smogn_boost\n",
        "#from ImbalancedLearningRegression import *\n",
        "import ImbalancedLearningRegression as iblr\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "do8cJ25c_HcF"
      },
      "source": [
        "# Data Description\n",
        "The dataset is sourced from Kaggle with a usability score of 10.0 (Source: https://www.kaggle.com/datasets/arashnic/imbalanced-data-practice). This data contains information about  and goal here is to predict whether an individual would be interested in vehicle insurance, denoted by response column \"response\". The target variable is highly imbalanced - 0: 319594, 1: 62531\n",
        "\n",
        "## Loading the Data\n",
        "Below, we load our data (Imbalanced Insurance Data set), In this case, we name our training set `data` and test data as 'test-data'. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RaFdQ2od-qVO"
      },
      "outputs": [],
      "source": [
        "#ds = pd.read_csv(\"https://raw.githubusercontent.com/paobranco/ImbalancedLearningRegression/SMOGNBoost/data/housing.csv\")\n",
        "#print(len(ds))\n",
        "\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/paobranco/ImbalancedLearningRegression/SMOGNBoost/data/housing.csv\")\n",
        "#ata = \"https://raw.githubusercontent.com/paobranco/ImbalancedLearningRegression/SMOGNBoost/data/College.csv\"\n",
        "#test_data = \"https://raw.githubusercontent.com/paobranco/ImbalancedLearningRegression/SMOGNBoost/data/CollegeTest.csv\"\n",
        "test_data = pd.read_csv(\"https://raw.githubusercontent.com/paobranco/ImbalancedLearningRegression/SMOGNBoost/data/housingTest.csv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D71nm6Co_KK-"
      },
      "source": [
        "## Introduction to SMOGNBoost\n",
        "Here we cover the focus of this example. We call the `smogn_boost` function from this package (`ImbalancedLearningRegression.smogn_boost`) and satisfy the minimum required arguments: `data` and `y`.\n",
        "\n",
        "* data: this argument takes a training data set\n",
        "* test_data: this argument takes a test data set\n",
        "* y: this argument takes a string, which specifies a response variable by header name \n",
        "* TotalIterations: this argument takes a positive integer, which specifies the total number of iterations\n",
        "* pert: perturbation / noise percentage\n",
        "* replace: sampling replacement (bool)\n",
        "* k: num of neighs for over-sampling (pos int)\n",
        "* error_threshold: this argument takes a positive integer, which specifies an error threshold \n",
        "* rel_thres: user defined relevance threshold \n",
        "* samp_method: \"balance or extreme\" - sampling method is perc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "dist_matrix: 100%|##########| 213/213 [00:49<00:00,  4.32it/s]\n",
            "synth_matrix: 100%|##########| 213/213 [00:09<00:00, 23.13it/s]\n",
            "r_index: 100%|##########| 83/83 [00:01<00:00, 43.69it/s]\n"
          ]
        }
      ],
      "source": [
        "## conduct smogn\n",
        "smogn = smogn(data, y=\"SalePrice\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qRV9hjPjJVF",
        "outputId": "9c4b115e-1e92-4f75-ecc5-f906fdf0cd6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A\n",
            "B\n",
            "C\n",
            "E\n",
            "F\n",
            "0.000693000693000693\n",
            "G\n",
            "[0.000693 0.000693 0.000693 ... 0.000693 0.000693 0.000693]\n",
            "H\n",
            "I\n",
            "J\n",
            "K\n",
            "L\n",
            "M\n",
            "N\n",
            "{'method': 'auto', 'num_pts': 3, 'ctrl_pts': [34900, 0, 0, 163000.0, 0, 0, 340000.0, 1, 0]}\n",
            "O\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ImbalancedLearningRegression\\ImbalancedLearningRegression\\smogn.py:103: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if y in data.columns.values is False:\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'SalePrice'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:155\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'SalePrice'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m## conduct smogn_boost\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m smogn_boost \u001b[39m=\u001b[39m smogn_boost(data, test_data, y\u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mSalePrice\u001b[39;49m\u001b[39m'\u001b[39;49m, TotalIterations\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, pert \u001b[39m=\u001b[39;49m \u001b[39m0.02\u001b[39;49m, replace \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, k \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m, error_threshold\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, rel_thres \u001b[39m=\u001b[39;49m \u001b[39m0.5\u001b[39;49m, samp_method \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mbalance\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\ImbalancedLearningRegression\\ImbalancedLearningRegression\\smogn_boost.py:133\u001b[0m, in \u001b[0;36msmogn_boost\u001b[1;34m(data, test_data, y, TotalIterations, pert, replace, k, error_threshold, rel_thres, samp_method)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m# loop while iteration is less than user provided iterations\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39mwhile\u001b[39;00m iteration \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m TotalIterations:\n\u001b[0;32m    131\u001b[0m \n\u001b[0;32m    132\u001b[0m     \u001b[39m# use initial training data set provided by user to obtain oversampled dataset using SMOGN, calculating it for the bumps\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     dt_over_sampled \u001b[39m=\u001b[39m smogn(data\u001b[39m=\u001b[39;49mdata, y \u001b[39m=\u001b[39;49m y_train, k \u001b[39m=\u001b[39;49m k)\n\u001b[0;32m    135\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    137\u001b[0m     \u001b[39m# splitting oversampled data for subsequent training data use below\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ImbalancedLearningRegression\\ImbalancedLearningRegression\\smogn.py:138\u001b[0m, in \u001b[0;36msmogn\u001b[1;34m(data, y, k, pert, samp_method, under_samp, drop_na_col, drop_na_row, replace, seed, rel_thres, rel_method, rel_xtrm_type, rel_coef, rel_ctrl_pts_rg)\u001b[0m\n\u001b[0;32m    135\u001b[0m     feat_dtypes_orig[j] \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39miloc[:, j]\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    137\u001b[0m \u001b[39m## determine column position for response variable y\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m y_col \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(y)\n\u001b[0;32m    140\u001b[0m \u001b[39m## move response variable y to last column\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m y_col \u001b[39m<\u001b[39m d \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'SalePrice'"
          ]
        }
      ],
      "source": [
        "## conduct smogn_boost\n",
        "smogn_boost = smogn_boost(data, test_data, y= 'SalePrice', TotalIterations=1, pert = 0.02, replace = False, k = 5, error_threshold=0.2, rel_thres = 0.5, samp_method = \"balance\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We read the test & training data and split them into features (X) and target value (Y)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read the test data and split features (X) and target value (Y)\n",
        "df_testData = pd.read_csv(test_data, header = 0)\n",
        "X_test = df_testData.drop(y, axis = 1)\n",
        "Y_test = df_testData[y]\n",
        "    \n",
        "# read the training data and split features (X) and target value (Y)\n",
        "df_data = pd.read_csv(data, header = 0)\n",
        "X_data = df_data.drop(y, axis = 1)\n",
        "Y_data = df_data[y]\n",
        "\n",
        "# set for clarity, name of target variable not data\n",
        "y_train = y"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below, we set an initial iteration as well as initialize empty arrays for the result, beta values, and decision tree predictions based on x_test. The array will store values over each iteration and be used to calculate the result after the final iteration (total iterations specified by the user)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set an initial iteration\n",
        "iteration = 1\n",
        "    \n",
        "# set an array of results, beta values, and decision tree predictions based on x_test\n",
        "result = np.empty(TotalIterations, dtype=int)\n",
        "beta = np.empty(TotalIterations, dtype=int)\n",
        "dt_test_predictions = np.empty(X_test, dtype=int)\n",
        "    \n",
        "# Dt(i) set distribution as 1/m weights, which is length of training data -1, as one of them is the target variable y \n",
        "weights = 1/(len(data))\n",
        "dt_distribution = np.zeros(len(data))\n",
        "for i in range(len(data)):\n",
        "    dt_distribution[i] = weights"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We call phi control and specificially the control points as it will be used when we apply SMOGN to oversample the imbalanced training data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# calling phi control\n",
        "pc = phi_ctrl_pts (y=y, method=\"auto\", xtrm_type = \"both\", coeff = 1.5, ctrl_pts=None)\n",
        "    \n",
        "# calling only the control points (third value) from the output\n",
        "rel_ctrl_pts_rg = pc[2]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below, we begin the main function which runs for the total iterations specified by the user.\n",
        "\n",
        "We obtain an oversampled dataset using SMOGN and our training dataset, split the oversampled data into features and a target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loop while iteration is less than user provided iterations\n",
        "while iteration <= TotalIterations:\n",
        "\n",
        "# use initial training data set provided by user to obtain oversampled dataset using SMOGN, calculating it for the bumps\n",
        "    dt_over_sampled = smogn(data=data, y_train = y_train, k = 5, pert = pert, replace=replace, rel_thres = rel_thres, rel_method = \"manual\", rel_ctrl_pts_rg = rel_ctrl_pts_rg)\n",
        "\n",
        "# splitting oversampled data for subsequent training data use below\n",
        "    df_oversampled = dt_over_sampled, header = 0\n",
        "    x_oversampled = df_oversampled.drop(y_train, axis = 1)\n",
        "    y_oversampled = df_oversampled[y_train]\n",
        "    \n",
        "# calls the decision tree and use it to achieve a new model, predict regression value for y (target response variable), and return the predicted values\n",
        "    dt_model = tree.DecisionTreeRegressor()\n",
        "        \n",
        "# train decision tree classifier\n",
        "    dt_model = dt_model.fit(x_oversampled, y_oversampled)\n",
        "        \n",
        "# predict the features in user provided data\n",
        "    dt_data_predictions = dt_model.predict(X_data)\n",
        "        \n",
        "# predict the features in user provided test data\n",
        "    dt_test_predictions.append(dt_model.predict(X_test))\n",
        "\n",
        "# initialize model error rate & epsilon t value\n",
        "    model_error = np.zeros(len(dt_data_predictions))\n",
        "    epsilon_t = 0\n",
        "\n",
        "# calculate the model error rate of the new model achieved earlier, as the delta between original dataset and predicted oversampled dataset\n",
        "# for each y in the dataset, calculate whether it is greater/lower than threshold and update accordingly\n",
        "    for i in range(len(dt_data_predictions)):\n",
        "        model_error[i] = abs((Y_data[i] - dt_data_predictions[i])/Y_data[i])\n",
        "        \n",
        "    for i in range(len(dt_data_predictions)):\n",
        "        if model_error[i] > error_threshold:\n",
        "            epsilon_t = epsilon_t + dt_distribution[i]\n",
        "                                      \n",
        "# beta is the update parameter of weights based on the model error rate calculated\n",
        "    beta.append(pow(epsilon_t, 2))\n",
        "\n",
        "# update the distribution weights\n",
        "    for i in dt_distribution:\n",
        "        if model_error[i] <= error_threshold:\n",
        "            dt_distribution[i] = dt_distribution[i] * beta\n",
        "        else:\n",
        "            dt_distribution[i] = dt_distribution[i]\n",
        "\n",
        "# normalize the distribution \n",
        "    dt_normalized = preprocessing.normalize(dt_distribution, max)\n",
        "\n",
        "# iteration count\n",
        "    iteration += 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below, we calculate the result outside the while loop. We split calculations into numerator and denominator calculating a series. To simplify the calculation, we use log(b) instead of (log(1/b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# calculate result\n",
        "numer = 0\n",
        "denom = 0\n",
        "    \n",
        "for b, i in zip(beta, dt_test_predictions):\n",
        "    numer += math.log(b) * i\n",
        "    denom += math.log(b)\n",
        "return numer/denom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSYCW_1t-zra"
      },
      "source": [
        "## Results\n",
        "After conducting SMOGNBoost, we briefly examine the results. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spqtcHX1yTfM",
        "outputId": "bfae806f-6e9c-4db7-a09d-0a7786e5d202"
      },
      "outputs": [],
      "source": [
        "## dimensions - original data \n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA5_E-5oQF18"
      },
      "source": [
        "## Conclusion\n",
        "TO DO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAQ5iGDJa2LM"
      },
      "source": [
        "## References\n",
        "\n",
        "Branco, P., Torgo, L., Ribeiro, R. (2017). SMOGN: A Pre-Processing Approach for Imbalanced Regression. Proceedings of Machine Learning Research, 74:36-50. http://proceedings.mlr.press/v74/branco17a/branco17a.pdf.\n",
        "\n",
        "Torgo, L., Ribeiro, R. P., Pfahringer, B., & Branco, P. (2013, September). Smote for regression. In Portuguese conference on artificial intelligence (pp. 378-389). Springer, Berlin, Heidelberg. https://researchcommons.waikato.ac.nz/bitstream/handle/10289/8518/smoteR.pdf?sequence=23\n",
        "\n",
        "Kunz, N. (2019). SMOGN: Synthetic Minority Over-Sampling for Regression with Gaussian Noise (Version 0.1.0). Python Package Index.\n",
        "https://pypi.org/project/smogn. \n",
        "\n",
        "Gareth, J., Daniela, W., Trevor, H., & Robert, T. (2013). An introduction to statistical learning: with applications in R. Spinger.\n",
        "http://www-bcf.usc.edu/~gareth/ISL/data.html.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SMOTE_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.9 ('ImbalancedLearningRegression')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "1c961f0653c6e1bdf33e63c7e72c10f24f14dece539fb6df7c7f98656204e204"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
